# Service to expose frontend
apiVersion: v1
kind: Service
metadata:
  name: frontend
spec:
  selector:
    app: frontend
  type: LoadBalancer
  ports:
  - name: http
    protocol: TCP
    port: 9090
    targetPort: 9090
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: frontend
---
# frontend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  labels:
    app: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
      annotations:
        "consul.hashicorp.com/connect-inject": "true"
        "consul.hashicorp.com/transparent-proxy": "false"        
        # Disabled TProxy b/c we are invoking the Lambda function without using a Terminating GW in this demo.
        # Term GW is recommanded but we're not using it for simplicy of the demo 
        # Terminating GW acts as the envoy proxy for the Lambda.
        # Without Term GW, there's nothing to enforce intentions or Tproxy on the Lambda function

#        "consul.hashicorp.com/connect-service-upstreams": "backend:9091"
        "consul.hashicorp.com/connect-service-upstreams": "backend-lambda-demo:9091"
    spec:
      serviceAccountName: frontend
      containers:
      - name: frontend
        image: nicholasjackson/fake-service:v0.22.4
        ports:
        - containerPort: 9090
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:9090"
        - name: "UPSTREAM_URIS"
          value: "http://localhost:9091" 
        - name: "NAME"
          value: "frontend"
        - name: "MESSAGE"
          value: "Hello World"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "false"
       
---
apiVersion: consul.hashicorp.com/v1alpha1
kind: ServiceDefaults
metadata:
  name: frontend
spec:
  protocol: "http"


